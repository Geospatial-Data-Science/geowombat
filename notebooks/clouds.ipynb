{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import geowombat as gw\n",
    "# from tsplanet import download_data\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import sklearn_crfsuite\n",
    "from affine import Affine\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_to_int_dict = dict(n=0, a=1, g=1, t=1, u=1, b=1, w=2, c=3, s=4, h=5)\n",
    "# str_to_int_dict = dict(n=0, a=1, g=2, t=3, u=4, b=5, w=6, c=7, s=8, h=9)\n",
    "str_to_int_dict = dict(n=0, l=1, u=2, w=3, c=4, s=5, h=6)\n",
    "\n",
    "int_to_str_dict = dict()\n",
    "for k, v in str_to_int_dict.items():\n",
    "    int_to_str_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(row):\n",
    "    str_values = row['class'].split(',')\n",
    "    return ','.join([str(str_to_int_dict[sv]) for sv in str_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_decoder(label):\n",
    "    return int_to_str_dict[label]\n",
    "\n",
    "\n",
    "def get_sample_xy(sample):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts a DataFrame sample to a CRF feature\n",
    "    \"\"\"\n",
    "    \n",
    "    date_diff = sample.date2.to_pydatetime().toordinal() - sample.date1.to_pydatetime().toordinal()\n",
    "    \n",
    "    b1_diff = int(sample.b1) - int(sample.b1_1)\n",
    "    b2_diff = int(sample.b2) - int(sample.b2_1)\n",
    "    b3_diff = int(sample.b3) - int(sample.b3_1)\n",
    "    b4_diff = int(sample.b4) - int(sample.b4_1)\n",
    "    b5_diff = int(sample.b5) - int(sample.b5_1)\n",
    "    b6_diff = int(sample.b6) - int(sample.b6_1)\n",
    "    \n",
    "    b1_diff_2 = int(sample.b1_2) - int(sample.b1)\n",
    "    b2_diff_2 = int(sample.b2_2) - int(sample.b2)\n",
    "    b3_diff_2 = int(sample.b3_2) - int(sample.b3)\n",
    "    b4_diff_2 = int(sample.b4_2) - int(sample.b4)\n",
    "    b5_diff_2 = int(sample.b5_2) - int(sample.b5)\n",
    "    b6_diff_2 = int(sample.b6_2) - int(sample.b6)\n",
    "    \n",
    "    diff1 = ['b1-diff1', 'b2-diff1', 'b3-diff1', 'b4-diff1', 'b5-diff1', 'b6-diff1']\n",
    "    diff2 = ['b1-diff2', 'b2-diff2', 'b3-diff2', 'b4-diff2', 'b5-diff2', 'b6-diff2']\n",
    "    \n",
    "    slab = band_names + ['date-diff'] + diff1 + diff2\n",
    "    \n",
    "    diff1_values = [b1_diff, b2_diff, b3_diff, b4_diff, b5_diff, b6_diff]\n",
    "    diff2_values = [b1_diff_2, b2_diff_2, b3_diff_2, b4_diff_2, b5_diff_2, b6_diff_2]\n",
    "    \n",
    "    sfea = np.array(sample[band_names].values.tolist() + [date_diff] + diff1_values + diff2_values, dtype='float64')\n",
    "\n",
    "    return dict(zip(slab, sfea)), label_decoder(int(sample.poly))\n",
    "\n",
    "\n",
    "def get_array_xy(sample):\n",
    "    return dict(zip(band_names, sample))\n",
    "\n",
    "    \n",
    "def samples_to_features(dfs):\n",
    "    \n",
    "    \"\"\"\n",
    "    sample = [[{t1}, {t2}, ..., {tn}], ..., [...]]\n",
    "    \"\"\"\n",
    "    \n",
    "    return [list(zip(*df.apply(get_sample_xy, axis=1))) for df in dfs]\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def sample_to_dict(array_sample):\n",
    "\n",
    "#     diff1 = ['b1-diff1', 'b2-diff1', 'b3-diff1', 'b4-diff1', 'b5-diff1', 'b6-diff1']\n",
    "#     diff2 = ['b1-diff2', 'b2-diff2', 'b3-diff2', 'b4-diff2', 'b5-diff2', 'b6-diff2']\n",
    "    \n",
    "#     slab = band_names + ['date-diff'] + diff1 + diff2\n",
    "    \n",
    "    slab = ['b'+str(r) for r in range(1, len(array_sample)+1)]\n",
    "\n",
    "    return dict(zip(slab, np.float64(array_sample)))    \n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def array_to_dict(*args):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts array sample to a CRF features\n",
    "    \"\"\"\n",
    "    \n",
    "    return [sample_to_dict(sample) for sample in args]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>s</td>\n",
       "      <td>t55kdu/cemsre_t55kdu_20171210_abbm5</td>\n",
       "      <td>POLYGON ((507064.648 7815065.614, 507064.648 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>s</td>\n",
       "      <td>t55kdu/cemsre_t55kdu_20171210_abbm5</td>\n",
       "      <td>POLYGON ((506948.752 7814128.218, 506948.752 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>s</td>\n",
       "      <td>t55kdu/cemsre_t55kdu_20171210_abbm5</td>\n",
       "      <td>POLYGON ((504307.000 7812038.678, 504307.000 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>s</td>\n",
       "      <td>t55kdu/cemsre_t55kdu_20171210_abbm5</td>\n",
       "      <td>POLYGON ((504047.938 7814997.439, 504047.938 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>s</td>\n",
       "      <td>t55kdu/cemsre_t55kdu_20171210_abbm5</td>\n",
       "      <td>POLYGON ((504361.540 7816885.866, 504361.540 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id label                                image  \\\n",
       "0  None     s  t55kdu/cemsre_t55kdu_20171210_abbm5   \n",
       "1  None     s  t55kdu/cemsre_t55kdu_20171210_abbm5   \n",
       "2  None     s  t55kdu/cemsre_t55kdu_20171210_abbm5   \n",
       "3  None     s  t55kdu/cemsre_t55kdu_20171210_abbm5   \n",
       "4  None     s  t55kdu/cemsre_t55kdu_20171210_abbm5   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((507064.648 7815065.614, 507064.648 7...  \n",
       "1  POLYGON ((506948.752 7814128.218, 506948.752 7...  \n",
       "2  POLYGON ((504307.000 7812038.678, 504307.000 7...  \n",
       "3  POLYGON ((504047.938 7814997.439, 504047.938 7...  \n",
       "4  POLYGON ((504361.540 7816885.866, 504361.540 7...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Landsat 8\n",
    "# rpath = Path('/media/jcgr/data/imagery/google/p225r083/brdf')\n",
    "# vpath = Path('/media/jcgr/data/imagery/google/training/p225r83.shp')\n",
    "\n",
    "# Sentinel 2\n",
    "rpath = Path('/scratch/rsc8/hardtkel/rapidfires/LW')\n",
    "vpath = Path('/scratch/rsc4/graesser/temp/s2/training/s2_training.shp')\n",
    "\n",
    "df = gpd.read_file(vpath.as_posix())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:04<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "image_ext = '.img'\n",
    "\n",
    "minrow = 1e9\n",
    "mincol = 1e9\n",
    "\n",
    "X_data = list()\n",
    "y_data = list()\n",
    "\n",
    "for row in tqdm(df.itertuples(index=True, name='Pandas'), total=df.shape[0]):\n",
    "    \n",
    "    with gw.open(rpath.joinpath(row.image + image_ext).as_posix(), chunks=64) as ds:\n",
    "        \n",
    "        clip = gw.clip(ds, df, query=\"index == {:d}\".format(row.Index), mask_data=False)\n",
    "        subset = clip.data.compute()\n",
    "        minrow = min(subset.shape[1], minrow)\n",
    "        mincol = min(subset.shape[2], mincol)\n",
    "        X_data.append(subset)\n",
    "        y_data.append(row.label)\n",
    "    \n",
    "X_data = np.array([d[:, :minrow, :mincol] for d in X_data], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 6, 7, 8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate N randomly sorted arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stack_features(barray, nrows, ncols):\n",
    "    \n",
    "#     z = np.zeros((nrows, ncols), dtype='uint64')\n",
    "    \n",
    "#     return np.concatenate(barray,\n",
    "#                           nir1_diff_array1[np.newaxis, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_list = list(map(str, list(range(0, X_data.shape[0]))))\n",
    "# int(np.random.choice(range(0, ntime), size=1, replace=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low = np.random.randint(0, high=int(ntime/2))\n",
    "# high = np.random.randint(low+2, high=ntime)\n",
    "# idx = [i + 1 for i in range(low, high)]\n",
    "\n",
    "# print(idx)\n",
    "\n",
    "# idx = np.random.choice(idx, size=len(idx), replace=False)\n",
    "\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1\n",
    "\n",
    "ntime, nbands, nrows, ncols = X_data.shape\n",
    "features = list()\n",
    "\n",
    "# Augment the data\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for a in range(0, n_iter):\n",
    "    \n",
    "    Xd = list()\n",
    "    yd = list()\n",
    "\n",
    "    low = np.random.randint(0, high=int(ntime/2))\n",
    "    high = np.random.randint(low+2, high=ntime)\n",
    "    idx_random = np.array([i + 1 for i in range(low, high)], dtype='int64')\n",
    "    \n",
    "    n_rand = len(idx_random)\n",
    "    \n",
    "    for i in range(0, n_rand*n_rand):\n",
    "\n",
    "        idx = np.random.choice(idx_random, size=n_rand, replace=False)\n",
    "        \n",
    "        Xd_ = [dlayer.transpose(1, 2, 0).reshape(nrows*ncols, nbands) for dlayer in X_data[idx]]\n",
    "        Xd_ = [array_to_dict(*[Xd_[j][i] for j in range(0, idx.shape[0])]) for i in range(0, nrows*ncols)]\n",
    "        y_ = [np.array(y_data)[idx].tolist() for i in range(0, nrows*ncols)]\n",
    "        \n",
    "        Xd.append(Xd_)\n",
    "        yd.append(y_)\n",
    "    \n",
    "    # time series of len(idx) x n_rand x n_rand\n",
    "    #Xd = np.vstack(Xd)\n",
    "    #niter = Xd.shape[0]\n",
    "    \n",
    "#     Xd = [dlayer.transpose(1, 2, 0).reshape(nrows*ncols, nbands) for dlayer in Xd]\n",
    "#     Xd = [array_to_dict(*[Xd[j][i] for j in range(0, niter)]) for i in range(0, nrows*ncols)]\n",
    "    \n",
    "#     yd = list(itertools.chain(*yd))\n",
    "#     yd = [[y_ for y_ in yd] for i in range(0, nrows*ncols)]\n",
    "    \n",
    "    X += Xd\n",
    "    y += yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random arrangements: 1\n",
      "Number of samples: 56\n",
      "Number of random arrangements x n samples: 576\n",
      "576\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "print('Number of random arrangements:', n_iter)\n",
    "print('Number of samples:', nrows*ncols)\n",
    "print('Number of random arrangements x n samples:', len(X))\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent using the limited-memory BFGS method (with L1 and L2 regularization)\n",
    "model = sklearn_crfsuite.CRF(algorithm='lbfgs', \n",
    "                             c1=0.001,\n",
    "                             c2=0.001,\n",
    "                             max_iterations=1000,\n",
    "                             num_memories=10,\n",
    "                             epsilon=0.0001,\n",
    "                             delta=0.0001,\n",
    "                             period=10,\n",
    "                             linesearch='StrongBacktracking',  # 'MoreThuente' 'Backtracking' 'StrongBacktracking'\n",
    "                             max_linesearch=20,\n",
    "                             all_possible_states=True,\n",
    "                             all_possible_transitions=True,\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=True, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.001, c2=0.001, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=0.0001, epsilon=0.0001,\n",
       "    error_sensitive=None, gamma=None, keep_tempfiles=None,\n",
       "    linesearch='StrongBacktracking', max_iterations=1000, max_linesearch=20,\n",
       "    min_freq=None, model_filename=None, num_memories=10, pa_type=None,\n",
       "    period=10, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6, 7, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [tlayer.transpose(1, 2, 0).reshape(nrows*ncols, nbands) for tlayer in X_data]\n",
    "features = [array_to_dict(*[features[j][i] for j in range(0, ntime)]) for i in range(0, nrows*ncols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_labels(model_pred):\n",
    "    \n",
    "    # samples x time x n classes\n",
    "    return np.array([[[ps['l'], ps['c'], ps['s']] for ps in p] for p in model_pred], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_to_labels(model.predict_marginals(features))\n",
    "pred = pred.transpose(1, 2, 0).reshape(ntime, pred.shape[2], nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3, 7, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: c\n",
      "\n",
      "Predicted l: 0.691359992688548\n",
      "Predicted c: 0.9999861713918057\n",
      "Predicted s: 4.4359133849923783e-07\n"
     ]
    }
   ],
   "source": [
    "time_index = 5\n",
    "# classes = ['l', 'u', 'w', 'c', 's', 'h']\n",
    "classes = ['l', 'c', 's']\n",
    "\n",
    "print('True:', y_data[time_index])\n",
    "print('')\n",
    "\n",
    "for j in range(0, len(classes)):\n",
    "    print('Predicted {}:'.format(classes[j]), pred[time_index][j].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=150)\n",
    "\n",
    "# Time n, mean over bands\n",
    "ax1.imshow(X_data[0].mean(axis=0), cmap='bone')\n",
    "\n",
    "# Time n, predicted probabilities for class k\n",
    "ax2.imshow(pred[0][1], cmap='plasma')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PlanetScope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_data('/scratch/rsc4/graesser/temp/planet',\n",
    "#               '/export/home/graesserj/code/python/github/planet/tsplanet/geojson/qld.geojson',\n",
    "#               '2019-08-01', \n",
    "#               '2019-08-10',\n",
    "#               cloud_cover=0.8,\n",
    "#               api_key='des')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples from training AOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_names(grid, filenames):\n",
    "    \n",
    "    rpath_dict = {'t55jel': '/scratch/rsc8/hardtkel/biocondition/biocondition/layers/sentinel/{}'.format(grid),\n",
    "                  't56jkt': '/scratch/rsc8/hardtkel/biocondition/biocondition/layers/sentinel/{}'.format(grid),\n",
    "                  't55kcu': '/scratch/rsc8/hardtkel/rapidfires/LW/{}'.format(grid),\n",
    "                  'l8': '/media/jcgr/data/imagery/google/p225r083/brdf'}\n",
    "    \n",
    "    NameInfo = namedtuple('NameInfo', 'rasters vector, time_names')\n",
    "    \n",
    "    #vector_dir = Path('/scratch/rsc4/graesser/temp/s2/training')\n",
    "    vector_dir = Path('/media/jcgr/data/imagery/google/training')\n",
    "    \n",
    "    image_dir = Path(rpath_dict[grid])\n",
    "    \n",
    "    filename_dict = dict()\n",
    "    for fn in filenames:\n",
    "        filename_dict[fn.split('_')[2]] = fn\n",
    "\n",
    "    sorted_names = list(zip(*sorted(filename_dict.items())))\n",
    "    \n",
    "    filenames = list(sorted_names[1])\n",
    "    \n",
    "    time_names = [datetime.strptime(t, '%Y%m%d') for t in list(sorted_names[0])]\n",
    "    \n",
    "    rasters = [image_dir.joinpath(fn).as_posix() for fn in filenames]\n",
    "    vector = vector_dir.joinpath('{}.shp'.format(grid)).as_posix()\n",
    "    \n",
    "    return NameInfo(rasters=rasters, vector=vector, time_names=time_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = fnmatch.filter(os.listdir(image_dir.as_posix()), '*.tif')\n",
    "\n",
    "filename_dict = dict()\n",
    "for fn in filenames:\n",
    "    filename_dict[fn.split('_')[3]] = fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_names = list(zip(*sorted(filename_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(sorted_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_names = [datetime.strptime(t, '%Y%m%d') for t in list(sorted_names[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = [image_dir.joinpath(fn).as_posix() for fn in filenames]\n",
    "vector = vector_dir.joinpath('p225r83.shp').as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gw.config.update(ref_image=rasters[0], \n",
    "#                       ref_res=(10, 10), \n",
    "#                       sensor='planetscope'):\n",
    "    \n",
    "#     with gw.open(rasters,\n",
    "#                  time_names=time_names,\n",
    "#                  how='intersection',\n",
    "#                  chunks=512) as ds:\n",
    "        \n",
    "#         dss = ds.mean(dim='time')\n",
    "#         dss.attrs = ds.attrs\n",
    "#         print(ds)\n",
    "        \n",
    "#         #dss.gw.imshow(band_names=['red', 'green', 'blue'], nodata=0, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(vector)\n",
    "\n",
    "df['class_len'] = df['class'].str.len()\n",
    "df['int_class'] = df.apply(str_to_int, axis=1)\n",
    "out = df['int_class'].str.split(',', expand=True)\n",
    "\n",
    "df_list = list()\n",
    "\n",
    "for s in range(0, out.shape[1]):\n",
    "    df_ = df.copy()\n",
    "    df_['id'] = out.iloc[:, s]\n",
    "    df_list.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "\n",
    "with gw.config.update(sensor='bgrn'):\n",
    "\n",
    "    with gw.open(rasters[0]) as ds:\n",
    "        transform = ds.transform\n",
    "\n",
    "    with gw.open(rasters, time_names=time_names) as ds:    \n",
    "\n",
    "        for ti, time in enumerate(ds.time.values):\n",
    "\n",
    "            dss = ds.sel(time=time)\n",
    "            dss.attrs = ds.attrs\n",
    "            dss.attrs['transform'] = transform\n",
    "\n",
    "            dfs.append(dss.gw.extract(df_list[ti]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert samples to CRF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ['blue', 'green', 'red', 'nir']\n",
    "label_name = 'poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = samples_to_features(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(zip(*results))[0]).T.tolist()\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(zip(*results))[1]).T.tolist()\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn_crfsuite.CRF(algorithm='lbfgs', # Gradient descent using the limited-memory BFGS method (with L1 and L2 regularization)\n",
    "            c1=0.01,\n",
    "            c2=0.01,\n",
    "            max_iterations=2000,\n",
    "            num_memories=10,\n",
    "            period=10,\n",
    "            epsilon=1e-04,\n",
    "            delta=1e-04,\n",
    "            linesearch='StrongBacktracking',  # 'MoreThuente' 'Backtracking' 'StrongBacktracking'\n",
    "            max_linesearch=20,\n",
    "            all_possible_states=True,\n",
    "            all_possible_transitions=True,\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_marginals(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples x time x n classes\n",
    "# pred = np.array([[[ps['land'], ps['cloud']] for ps in p] for p in model.predict_marginals(X)], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the data to predict on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gw.config.update(sensor='rgbn'):\n",
    "    \n",
    "    with gw.open(rasters[0]) as ds:\n",
    "        #print(ds.data.max().compute())\n",
    "        transform = ds.transform\n",
    "    \n",
    "    with gw.open(rasters, time_names=time_names) as ds:\n",
    "        \n",
    "        ds.attrs['transform'] = transform\n",
    "        \n",
    "        dss = ds[:, :, 3000:3512, 3000:3512].chunk((1, 256, 256)).fillna(0)\n",
    "        #dss = gw.subset(ds, left=315416.003, top=-3611632.029, rows=500, cols=500).chunk((1, 1, 64, 64))\n",
    "        #print(dss)\n",
    "        #print(dss.data.max().compute())\n",
    "        test = dss.astype('float64').data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime, nbands, nrows, ncols = test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the array to CRF-compatible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [tlayer.transpose(1, 2, 0).reshape(nrows*ncols, nbands) for tlayer in test]\n",
    "features = [array_to_dict(*[features[j][i] for j in range(0, ntime)]) for i in range(0, nrows*ncols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on all time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_marginals(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_labels(model_pred):\n",
    "    \n",
    "    # samples x time x n classes\n",
    "    return np.array([[[ps['n'], ps['l'], ps['w'], ps['c'], ps['s'], ps['h']] for ps in p] for p in model_pred], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples x time x n classes\n",
    "# pred = np.array([[[ps['n'], ps['l'], ps['w'], ps['c'], ps['s'], ps['h']] for ps in p] \n",
    "#                  for p in model.predict_marginals(features)], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_to_labels(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.transpose(1, 2, 0).reshape(ntime, pred.shape[2], nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot cloud probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(pred.shape[0], 2, dpi=400, figsize=(2, 12))\n",
    "\n",
    "bidx = 0 # band index\n",
    "cidx = 3 # class index\n",
    "\n",
    "for pi in range(0, pred.shape[0]):\n",
    "\n",
    "    ip = test[pi, bidx, :, :]\n",
    "    ip[ip == 0] = np.nan\n",
    "    \n",
    "    axes[pi][0].imshow(ip, vmin=np.nanpercentile(ip, 10), vmax=np.nanpercentile(ip, 90), cmap='plasma')\n",
    "    #axes[pi][1].imshow(pred[pi, cidx, :, :], vmin=0, vmax=1, cmap='plasma')\n",
    "    axes[pi][1].imshow(pred[pi, :, :, :].argmax(axis=0), vmin=0, vmax=5)\n",
    "    \n",
    "#     axes[pi][0].set_xlabel('Time {:d}'.format(pi+1))\n",
    "    \n",
    "    axes[pi][0].axis('off')\n",
    "    axes[pi][1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.arange(8*3*2).reshape(8,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 1\n",
    "# a[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 2\n",
    "# a[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.transpose(1, 2, 0).reshape(3, 2, 2, 4)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
